# BERT-NMT
BSc Thesis Project: Incorporating BERT into Neural Machine Translation for Low-Resource Languages

This research aims to improve upon automatic language translation systems, specifically for low-resource languages (LRLs), by implementing and fine-tuning the BERT-fused model proposed by Zhu et al. (2020), which has been shown to set new state-of-the-art translation results in using both supervised and unsupervised learning. 
The goal is to determine how BERT can best be used to improve neural machine translation (NMT) and to fine-tune a model for English-Irish translation in an attempt to set a new standard. 
The paper will focus on the Englishâ€“Irish translation pair, of which Irish is an LRL. 
Irish has been chosen due to its familiarity to me and will provide a suitable challenge for MT, as its structure is relatively different from English, while still using the same writing system and belonging to the same broader language family. 
