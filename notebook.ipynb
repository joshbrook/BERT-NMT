{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom keras import layers\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom keras.losses import sparse_categorical_crossentropy\n\n#!pip install keras-nlp\n#from keras_nlp.layers import PositionEmbedding, TransformerEncoder, TransformerDecoder","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:12:37.564189Z","iopub.execute_input":"2023-03-04T15:12:37.564994Z","iopub.status.idle":"2023-03-04T15:12:45.718729Z","shell.execute_reply.started":"2023-03-04T15:12:37.564956Z","shell.execute_reply":"2023-03-04T15:12:45.717441Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"small = pd.read_csv(\"/kaggle/input/bert-nmt/pairs.tsv\", sep='\\t', usecols=[1,3], names=['English', 'Gaeilge'])\ndcep = pd.read_csv(\"/kaggle/input/dcep-bisentences/EN-GA-bisentences.txt\", sep='\\t', names=['English', 'Gaeilge'])\n\npairs = pd.concat([small, dcep])\npairs.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:39.794446Z","iopub.execute_input":"2023-03-04T15:13:39.795630Z","iopub.status.idle":"2023-03-04T15:13:40.137811Z","shell.execute_reply.started":"2023-03-04T15:13:39.795589Z","shell.execute_reply":"2023-03-04T15:13:40.136564Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                 English  \\\n11529  coordination of the Union's structural instrum...   \n31679  Only officials of the European Parliament and ...   \n9093                                                74 c   \n22904  Procedure for the consideration and adoption o...   \n42596            Verification of financial compatibility   \n\n                                                 Gaeilge  \n11529   comhordú ar ionstraimí struchtúracha an Aontais,  \n31679  Ní bheidh gá ach amháin ag oifigigh de chuid P...  \n9093                                                74 c  \n22904  Nós imeachta maidir le breithniú agus glacadh ...  \n42596                  Comhréireacht airgeadais a fhíorú  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Gaeilge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11529</th>\n      <td>coordination of the Union's structural instrum...</td>\n      <td>comhordú ar ionstraimí struchtúracha an Aontais,</td>\n    </tr>\n    <tr>\n      <th>31679</th>\n      <td>Only officials of the European Parliament and ...</td>\n      <td>Ní bheidh gá ach amháin ag oifigigh de chuid P...</td>\n    </tr>\n    <tr>\n      <th>9093</th>\n      <td>74 c</td>\n      <td>74 c</td>\n    </tr>\n    <tr>\n      <th>22904</th>\n      <td>Procedure for the consideration and adoption o...</td>\n      <td>Nós imeachta maidir le breithniú agus glacadh ...</td>\n    </tr>\n    <tr>\n      <th>42596</th>\n      <td>Verification of financial compatibility</td>\n      <td>Comhréireacht airgeadais a fhíorú</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train = pairs.sample(frac=0.8)\nval = pairs.drop(train.index)\n\nprint(f\"{len(pairs)} total pairs\")\nprint(f\"{len(train)} training pairs\")\nprint(f\"{len(val)} validation pairs\")","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:40.140893Z","iopub.execute_input":"2023-03-04T15:13:40.141771Z","iopub.status.idle":"2023-03-04T15:13:40.407368Z","shell.execute_reply.started":"2023-03-04T15:13:40.141737Z","shell.execute_reply":"2023-03-04T15:13:40.406200Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"48806 total pairs\n39045 training pairs\n9035 validation pairs\n","output_type":"stream"}]},{"cell_type":"code","source":"size = 15000\nseq_len = 20\nbatch = 64\n\nen_vec = layers.TextVectorization(max_tokens=size, output_mode=\"int\", output_sequence_length=seq_len)\nga_vec = layers.TextVectorization(max_tokens=size, output_mode=\"int\", output_sequence_length=seq_len+1)\n\nen_vec.adapt(pairs[\"English\"])\nga_vec.adapt(pairs[\"Gaeilge\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:40.409605Z","iopub.execute_input":"2023-03-04T15:13:40.409980Z","iopub.status.idle":"2023-03-04T15:13:52.543276Z","shell.execute_reply.started":"2023-03-04T15:13:40.409940Z","shell.execute_reply":"2023-03-04T15:13:52.542098Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def format_dataset(en, ga):\n    en = en_vec(en)\n    ga = ga_vec(ga)\n    return ({\"encoder_inputs\": en, \"decoder_inputs\": ga[:, :-1],}, ga[:, 1:])\n\ndef make_dataset(en, ga):\n    dataset = tf.data.Dataset.from_tensor_slices((en, ga))\n    dataset = dataset.batch(batch)\n    dataset = dataset.map(format_dataset)\n    return dataset.shuffle(2048).prefetch(16).cache()\n\nds = make_dataset(train[\"English\"], train[\"Gaeilge\"])\nval_ds = make_dataset(val[\"English\"], val[\"Gaeilge\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:52.549091Z","iopub.execute_input":"2023-03-04T15:13:52.550013Z","iopub.status.idle":"2023-03-04T15:13:52.783469Z","shell.execute_reply.started":"2023-03-04T15:13:52.549971Z","shell.execute_reply":"2023-03-04T15:13:52.782155Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"A chained-together TransformerEncoder and TransformerDecoder makes up our sequence-to-sequence Transformer. A PositionalEmbedding layer is also used to inform the model of word order.\n\nThe TransformerEncoder will receive the original sequence and create a new representation. The TransformerDecoder will then receive this modified representation and the current target sequence (target words 0 to N). The TransformerDecoder will next try to anticipate the following words (up to N+1) in the target sequence.\n\nCausal masking is a crucial component that enables this (see TransformerDecoder function get causal attention mask() for more information). We must ensure that the TransformerDecoder only takes data from target tokens 0 to N when predicting token N+1 because it sees the full sequences at once.","metadata":{}},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n        attention_output = self.attention(\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n        )\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.token_embeddings = layers.Embedding(\n            input_dim=vocab_size, output_dim=embed_dim\n        )\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=embed_dim\n        )\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n\n\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        causal_mask = self.get_causal_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n            padding_mask = tf.minimum(padding_mask, causal_mask)\n\n        attention_output_1 = self.attention_1(\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n        )\n        out_1 = self.layernorm_1(inputs + attention_output_1)\n\n        attention_output_2 = self.attention_2(\n            query=out_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=padding_mask,\n        )\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\n\n        proj_output = self.dense_proj(out_2)\n        return self.layernorm_3(out_2 + proj_output)\n\n    def get_causal_attention_mask(self, inputs):\n        input_shape = tf.shape(inputs)\n        batch_size, sequence_length = input_shape[0], input_shape[1]\n        i = tf.range(sequence_length)[:, tf.newaxis]\n        j = tf.range(sequence_length)\n        mask = tf.cast(i >= j, dtype=\"int32\")\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n            axis=0,\n        )\n        return tf.tile(mask, mult)","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:52.784960Z","iopub.execute_input":"2023-03-04T15:13:52.785309Z","iopub.status.idle":"2023-03-04T15:13:52.807461Z","shell.execute_reply.started":"2023-03-04T15:13:52.785271Z","shell.execute_reply":"2023-03-04T15:13:52.806273Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def create_model(embed_dim, latent_dim, num_heads):\n    encoder_inputs = layers.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n    pos = PositionalEmbedding(seq_len, size, embed_dim)(encoder_inputs)\n    encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(pos)\n    encoder = Model(encoder_inputs, encoder_outputs)\n\n    decoder_inputs = layers.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n    encoded_seq_inputs = layers.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n    x = PositionalEmbedding(seq_len, size, embed_dim)(decoder_inputs)\n    x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n    x = layers.Dropout(0.5)(x)\n    decoder_outputs = layers.Dense(size, activation=\"softmax\")(x)\n    decoder = Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n\n    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n    transformer = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n    \n    return transformer","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:52.811089Z","iopub.execute_input":"2023-03-04T15:13:52.811943Z","iopub.status.idle":"2023-03-04T15:13:52.821383Z","shell.execute_reply.started":"2023-03-04T15:13:52.811902Z","shell.execute_reply":"2023-03-04T15:13:52.820412Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"epochs = 30  # This should be at least 30 for convergence\nembed_dim = 256\nlatent_dim = 2048\nnum_heads = 64\n\ntransformer = create_model(embed_dim, latent_dim, num_heads)\ntransformer.summary()\ntransformer.compile(\n    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)\ntransformer.fit(ds, epochs=epochs, validation_data=val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-04T15:13:52.824618Z","iopub.execute_input":"2023-03-04T15:13:52.825023Z","iopub.status.idle":"2023-03-04T16:15:44.248994Z","shell.execute_reply.started":"2023-03-04T15:13:52.824995Z","shell.execute_reply":"2023-03-04T16:15:44.247795Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"transformer\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n                                                                                                  \n positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n alEmbedding)                                                                                     \n                                                                                                  \n decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n                                                                                                  \n transformer_encoder (Transform  (None, None, 256)   17878528    ['positional_embedding[0][0]']   \n erEncoder)                                                                                       \n                                                                                                  \n model_1 (Functional)           (None, None, 15000)  42405784    ['decoder_inputs[0][0]',         \n                                                                  'transformer_encoder[0][0]']    \n                                                                                                  \n==================================================================================================\nTotal params: 64,129,432\nTrainable params: 64,129,432\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/30\n611/611 [==============================] - 136s 205ms/step - loss: 4.6578 - accuracy: 0.2419 - val_loss: 3.2496 - val_accuracy: 0.3863\nEpoch 2/30\n611/611 [==============================] - 109s 179ms/step - loss: 2.8961 - accuracy: 0.4399 - val_loss: 2.0746 - val_accuracy: 0.5671\nEpoch 3/30\n611/611 [==============================] - 109s 179ms/step - loss: 1.9382 - accuracy: 0.5967 - val_loss: 1.4482 - val_accuracy: 0.7132\nEpoch 4/30\n611/611 [==============================] - 109s 179ms/step - loss: 1.2566 - accuracy: 0.7343 - val_loss: 0.7961 - val_accuracy: 0.8426\nEpoch 5/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.8003 - accuracy: 0.8354 - val_loss: 0.5258 - val_accuracy: 0.9091\nEpoch 6/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.5876 - accuracy: 0.8812 - val_loss: 0.4191 - val_accuracy: 0.9333\nEpoch 7/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.4617 - accuracy: 0.9071 - val_loss: 0.4181 - val_accuracy: 0.9323\nEpoch 8/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.3708 - accuracy: 0.9260 - val_loss: 0.3318 - val_accuracy: 0.9536\nEpoch 9/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.3061 - accuracy: 0.9388 - val_loss: 0.3129 - val_accuracy: 0.9583\nEpoch 10/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.2614 - accuracy: 0.9480 - val_loss: 0.2973 - val_accuracy: 0.9639\nEpoch 11/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.2275 - accuracy: 0.9545 - val_loss: 0.2879 - val_accuracy: 0.9656\nEpoch 12/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.1988 - accuracy: 0.9602 - val_loss: 0.2908 - val_accuracy: 0.9661\nEpoch 13/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.1787 - accuracy: 0.9639 - val_loss: 0.2786 - val_accuracy: 0.9695\nEpoch 14/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.1578 - accuracy: 0.9680 - val_loss: 0.2761 - val_accuracy: 0.9701\nEpoch 15/30\n611/611 [==============================] - 110s 179ms/step - loss: 0.1453 - accuracy: 0.9703 - val_loss: 0.2741 - val_accuracy: 0.9710\nEpoch 16/30\n611/611 [==============================] - 110s 180ms/step - loss: 0.1295 - accuracy: 0.9736 - val_loss: 0.2759 - val_accuracy: 0.9719\nEpoch 17/30\n611/611 [==============================] - 110s 179ms/step - loss: 0.1175 - accuracy: 0.9761 - val_loss: 0.2774 - val_accuracy: 0.9717\nEpoch 18/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.1089 - accuracy: 0.9780 - val_loss: 0.2814 - val_accuracy: 0.9728\nEpoch 19/30\n611/611 [==============================] - 110s 179ms/step - loss: 0.1004 - accuracy: 0.9795 - val_loss: 0.2755 - val_accuracy: 0.9727\nEpoch 20/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.0947 - accuracy: 0.9807 - val_loss: 0.2768 - val_accuracy: 0.9727\nEpoch 21/30\n611/611 [==============================] - 110s 179ms/step - loss: 0.0883 - accuracy: 0.9822 - val_loss: 0.2818 - val_accuracy: 0.9728\nEpoch 22/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.0832 - accuracy: 0.9831 - val_loss: 0.2828 - val_accuracy: 0.9723\nEpoch 23/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.0773 - accuracy: 0.9844 - val_loss: 0.2862 - val_accuracy: 0.9729\nEpoch 24/30\n611/611 [==============================] - 119s 195ms/step - loss: 0.0738 - accuracy: 0.9849 - val_loss: 0.2894 - val_accuracy: 0.9723\nEpoch 25/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.0703 - accuracy: 0.9857 - val_loss: 0.2845 - val_accuracy: 0.9735\nEpoch 26/30\n611/611 [==============================] - 110s 180ms/step - loss: 0.0666 - accuracy: 0.9864 - val_loss: 0.2888 - val_accuracy: 0.9742\nEpoch 27/30\n611/611 [==============================] - 110s 180ms/step - loss: 0.0632 - accuracy: 0.9872 - val_loss: 0.2817 - val_accuracy: 0.9736\nEpoch 28/30\n611/611 [==============================] - 110s 180ms/step - loss: 0.0612 - accuracy: 0.9875 - val_loss: 0.2901 - val_accuracy: 0.9734\nEpoch 29/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.0588 - accuracy: 0.9880 - val_loss: 0.2932 - val_accuracy: 0.9738\nEpoch 30/30\n611/611 [==============================] - 109s 179ms/step - loss: 0.0567 - accuracy: 0.9883 - val_loss: 0.2927 - val_accuracy: 0.9739\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f8493807410>"},"metadata":{}}]},{"cell_type":"code","source":"ga_vocab = ga_vec.get_vocabulary()\nga_index_lookup = dict(zip(range(len(ga_vocab)), ga_vocab))\nmax_decoded_sentence_length = 20\n\n\ndef decode_sequence(model, input_sentence):\n    tokenized_input_sentence = en_vec([input_sentence])\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = ga_vec([decoded_sentence])[:, :-1]\n        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n\n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = ga_index_lookup[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n\n        if sampled_token == \"[end]\":\n            break\n    return decoded_sentence\n\n\nfor _ in range(10):\n    input_sentence = random.choice(pairs[\"English\"])\n    translated = decode_sequence(transformer, input_sentence)\n    print(input_sentence, \"\\n\", translated, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-03-04T16:31:16.170715Z","iopub.execute_input":"2023-03-04T16:31:16.171311Z","iopub.status.idle":"2023-03-04T16:31:26.282669Z","shell.execute_reply.started":"2023-03-04T16:31:16.171272Z","shell.execute_reply":"2023-03-04T16:31:26.281473Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Delegated acts \n [start] an coiste freagrach as páirtithe polaitiúla               \n\nIn the event of a crisis or at the request of the President of the European Parliament or of the Chairman of the Committee on Foreign Affairs, Human Rights, Common Security and Defence Policy, such information shall be provided at the earliest opportunity. \n [start] cur chun feidhme nó cathaoirleach an choiste um an iarraidh ar an iarraidh ar an eolas nó ar aghaidh chuig \n\nThe President shall obtain the agreement of Parliament to putting such amendments to the vote. \n [start] an tuachtarán a fháil ar a lorg sula ndéanfaidh sé an leasuithe         \n\nThe questions and answers shall be published in the \n [start] na ceisteanna agus na freagraí in               \n\nCommittee on Budgets \n [start] an coiste um buiséid                 \n\nCommittee on Petitions \n [start] an coiste um achainíocha                 \n\nDisputes on voting \n [start] an tuachtarán an vótáil                 \n\nManagers shall have the duty of knowing those of their staff who are engaged in work on classified information or who have access to secure communication or information systems, and to record and report any incidents or apparent vulnerabilities which are likely to affect security. \n [start] sé a choimeád ar bun chun cinn ó rúnaíocht an duine a bhfuil daoine nádúrtha nó a bhfoireann atá ag \n\nEnhanced cooperation between Member States \n [start] feabhsaithe idir ballstáit                  \n\nAnnual and other reports of other institutions on which the Treaties provide for consultation of the European Parliament or other legal provisions require an opinion by the European Parliament shall be dealt with in a report submitted to the plenary. \n [start] tuarascálacha bliantúla agus tuarascálacha eile ó institiúidí eile ar bhonn a dhéantar an chomhphobail maidir le nuair a dhéantar an \n\n","output_type":"stream"}]},{"cell_type":"code","source":"transformer.save_weights(\"weights\")","metadata":{"execution":{"iopub.status.busy":"2023-03-04T16:39:11.966161Z","iopub.execute_input":"2023-03-04T16:39:11.967105Z","iopub.status.idle":"2023-03-04T16:39:13.012855Z","shell.execute_reply.started":"2023-03-04T16:39:11.967066Z","shell.execute_reply":"2023-03-04T16:39:13.011398Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"new_model = create_model(embed_dim, latent_dim, num_heads)\nnew_model.load_weights(\"weights\")\nnew_model","metadata":{"execution":{"iopub.status.busy":"2023-03-04T16:39:14.523674Z","iopub.execute_input":"2023-03-04T16:39:14.524632Z","iopub.status.idle":"2023-03-04T16:39:15.435535Z","shell.execute_reply.started":"2023-03-04T16:39:14.524579Z","shell.execute_reply":"2023-03-04T16:39:15.434472Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<keras.engine.functional.Functional at 0x7f83c00f4e90>"},"metadata":{}}]},{"cell_type":"code","source":"inp = \"The parliament decided on the regulation\"\n\ntranslated = decode_sequence(new_model, inp)\nprint(inp, \"\\n\", translated, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-03-04T16:39:48.943481Z","iopub.execute_input":"2023-03-04T16:39:48.943978Z","iopub.status.idle":"2023-03-04T16:39:50.192877Z","shell.execute_reply.started":"2023-03-04T16:39:48.943933Z","shell.execute_reply":"2023-03-04T16:39:50.191579Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"The parliament decided on the regulation \n [start] an pharlaimint cinneadh ar an moladh ón gcomhairle             \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}